{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daily.2019-09-01_09-29-01.csv',\n",
       " 'daily.2019-09-03_03-44-01.csv',\n",
       " 'daily.2019-09-04_23-23-01.csv',\n",
       " 'daily.2019-09-06_20-34-01.csv',\n",
       " 'daily.2019-09-09_01-34-02.csv',\n",
       " 'daily.2019-09-11_05-40-02.csv',\n",
       " 'daily.2019-09-13_04-11-01.csv',\n",
       " 'daily.2019-09-15_01-41-01.csv',\n",
       " 'daily.2019-09-16_19-44-01.csv',\n",
       " 'daily.2019-09-18_14-08-01.csv',\n",
       " 'daily.2019-09-20_12-49-01.csv',\n",
       " 'daily.2019-09-22_07-40-01.csv',\n",
       " 'daily.2019-09-24_05-05-02.csv']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_list = []\n",
    "\n",
    "LUIGI_LOG_PATH = '/usr/local/trustyou/home/andream/nfs/processmining/pm4pyexample/'\n",
    "LUIGI_LOG_PATH = '/usr/local/trustyou/home/andream/nfs/processmining/minilogs/daily/logs/'\n",
    "#LUIGI_LOG_PATH = '/usr/local/trustyou/home/andream/nfs/processmining/minilogs/table-precomp/logs/tch/'\n",
    "#LUIGI_LOG_PATH='/usr/local/trustyou/home/andream/nfs/processmining/minilogs/table-precomp/logs/october/mongo/'\n",
    "for filename in os.listdir(LUIGI_LOG_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        log_path = LUIGI_LOG_PATH+'/'+filename\n",
    "        csv_list.append(filename)\n",
    "appended_df = pd.DataFrame()\n",
    "#appended_df\n",
    "csv_list.sort()\n",
    "csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher \n",
    "  \n",
    "def longestSubstring(str1,str2): \n",
    "  \n",
    "     # initialize SequenceMatcher object with  \n",
    "     # input string \n",
    "     seqMatch = SequenceMatcher(None,str1,str2) \n",
    "  \n",
    "     # find match of longest sub-string \n",
    "     # output will be like Match(a=0, b=0, size=5) \n",
    "     match = seqMatch.find_longest_match(0, len(str1), 0, len(str2)) \n",
    "  \n",
    "     # print longest substring \n",
    "     if (match.size!=0): \n",
    "          result = str1[match.a: match.a + match.size]\n",
    "          print (result)  \n",
    "          return result\n",
    "     else: \n",
    "          print ('No longest common sub-string found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily.2019-09-\n",
      "/usr/local/trustyou/home/andream/nfs/processmining/minilogs/daily/logs//../catts_daily.2019-09-.csv\n"
     ]
    }
   ],
   "source": [
    "PROCESS_NAME = longestSubstring(csv_list[0],csv_list[-1])\n",
    "OUTPUT_CATT_PATH = LUIGI_LOG_PATH+'/../catts_'+str(PROCESS_NAME)+'.csv'\n",
    "print(OUTPUT_CATT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...  daily.2019-09-04_23-23-01.csv\n",
      "Preprocessing...  daily.2019-09-09_01-34-02.csv\n",
      "Preprocessing...  daily.2019-09-16_19-44-01.csv\n",
      "Preprocessing...  daily.2019-09-20_12-49-01.csv\n",
      "Preprocessing...  daily.2019-09-24_05-05-02.csv\n",
      "Preprocessing...  daily.2019-09-11_05-40-02.csv\n",
      "Preprocessing...  daily.2019-09-13_04-11-01.csv\n",
      "Preprocessing...  daily.2019-09-06_20-34-01.csv\n",
      "Preprocessing...  daily.2019-09-18_14-08-01.csv\n",
      "Preprocessing...  daily.2019-09-15_01-41-01.csv\n",
      "Preprocessing...  daily.2019-09-03_03-44-01.csv\n",
      "Preprocessing...  daily.2019-09-22_07-40-01.csv\n",
      "Preprocessing...  daily.2019-09-01_09-29-01.csv\n",
      "31469\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>task</th>\n",
       "      <th>state</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-04 23:23:20</td>\n",
       "      <td>AllTasks</td>\n",
       "      <td>start</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=daily_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n</td>\n",
       "      <td>start</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=regular_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n</td>\n",
       "      <td>start</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=reprocess_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n</td>\n",
       "      <td>start</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>ProxySetupTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep)\\n</td>\n",
       "      <td>start</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  \\\n",
       "0  2019-09-04 23:23:20   \n",
       "1  2019-09-04 23:35:08   \n",
       "2  2019-09-04 23:35:08   \n",
       "3  2019-09-04 23:35:08   \n",
       "4  2019-09-04 23:35:08   \n",
       "\n",
       "                                                                                                                                                                                                                      task  \\\n",
       "0  AllTasks                                                                                                                                                                                                                  \n",
       "1  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=daily_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n       \n",
       "2  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=regular_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n     \n",
       "3  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=reprocess_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n   \n",
       "4  ProxySetupTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep)\\n                                                                                                                                     \n",
       "\n",
       "   state                    source_file  \n",
       "0  start  daily.2019-09-04_23-23-01.csv  \n",
       "1  start  daily.2019-09-04_23-23-01.csv  \n",
       "2  start  daily.2019-09-04_23-23-01.csv  \n",
       "3  start  daily.2019-09-04_23-23-01.csv  \n",
       "4  start  daily.2019-09-04_23-23-01.csv  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for filename in os.listdir(LUIGI_LOG_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        log_path = LUIGI_LOG_PATH+'/'+filename\n",
    "        print('Preprocessing... ', filename)\n",
    "        df = pd.read_csv(log_path, index_col=0)\n",
    "        df = df[['timestamp','task','state']]\n",
    "        df['source_file'] = filename\n",
    "\n",
    "        df['state'][0]='start'\n",
    "        df['task'][0]='AllTasks'\n",
    "\n",
    "        df['state'][len(df)-1]='done'\n",
    "        df['task'][len(df)-1]='AllTasks'\n",
    "        \n",
    "        appended_df = appended_df.append(df)\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(len(appended_df))\n",
    "appended_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task(task_call):\n",
    "    if isinstance(task_call, float):\n",
    "        return task_call\n",
    "    return task_call.split('(')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start entries:  15729\n",
      "End entries:  15699\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>state</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>task_call</th>\n",
       "      <th>source_file</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AllTasks</td>\n",
       "      <td>start</td>\n",
       "      <td>2019-09-04 23:23:20</td>\n",
       "      <td>AllTasks</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>2019-09-04 23:23:20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DumpTask</td>\n",
       "      <td>start</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=daily_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DumpTask</td>\n",
       "      <td>start</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=regular_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DumpTask</td>\n",
       "      <td>start</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=reprocess_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ProxySetupTask</td>\n",
       "      <td>start</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>ProxySetupTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep)\\n</td>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        task_name  state            timestamp  \\\n",
       "0  AllTasks        start  2019-09-04 23:23:20   \n",
       "1  DumpTask        start  2019-09-04 23:35:08   \n",
       "2  DumpTask        start  2019-09-04 23:35:08   \n",
       "3  DumpTask        start  2019-09-04 23:35:08   \n",
       "4  ProxySetupTask  start  2019-09-04 23:35:08   \n",
       "\n",
       "                                                                                                                                                                                                                 task_call  \\\n",
       "0  AllTasks                                                                                                                                                                                                                  \n",
       "1  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=daily_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n       \n",
       "2  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=regular_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n     \n",
       "3  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=reprocess_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n   \n",
       "4  ProxySetupTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep)\\n                                                                                                                                     \n",
       "\n",
       "                     source_file           start_time end_time  \n",
       "0  daily.2019-09-04_23-23-01.csv  2019-09-04 23:23:20  NaN      \n",
       "1  daily.2019-09-04_23-23-01.csv  2019-09-04 23:35:08  NaN      \n",
       "2  daily.2019-09-04_23-23-01.csv  2019-09-04 23:35:08  NaN      \n",
       "3  daily.2019-09-04_23-23-01.csv  2019-09-04 23:35:08  NaN      \n",
       "4  daily.2019-09-04_23-23-01.csv  2019-09-04 23:35:08  NaN      "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = appended_df\n",
    "df['task_call'] = df['task']\n",
    "df['task_name'] = np.where(df['task'].notnull(), df['task'].apply(get_task), df['task'])\n",
    "df = df[['task_name','state','timestamp','task_call', 'source_file']]\n",
    "\n",
    "df['start_time'] = np.where(df['state']=='start', df['timestamp'], np.nan)\n",
    "df['end_time'] = np.where(df['state']=='done', df['timestamp'], np.nan)\n",
    "\n",
    "start_df = df[df['state']=='start']\n",
    "print('Start entries: ',len(start_df))\n",
    "\n",
    "end_df = df[df['state']=='done']\n",
    "print('End entries: ',len(end_df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15711\n"
     ]
    }
   ],
   "source": [
    "tt = pd.merge(start_df, end_df, on=['task_call', 'source_file'], how='outer')\n",
    "tt = tt[tt['start_time_x'].notnull()]\n",
    "tt = tt[tt['end_time_y'].notnull()]\n",
    "\n",
    "tt['case'] = tt['source_file']\n",
    "tt['activity'] = tt['task_name_x']\n",
    "tt['start_time'] = tt['start_time_x']\n",
    "tt['end_time'] = tt['end_time_y']\n",
    "print(len(tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save catt to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15711\n",
      "                            case        activity           start_time  \\\n",
      "0  daily.2019-09-04_23-23-01.csv  AllTasks        2019-09-04 23:23:20   \n",
      "1  daily.2019-09-04_23-23-01.csv  DumpTask        2019-09-04 23:35:08   \n",
      "2  daily.2019-09-04_23-23-01.csv  DumpTask        2019-09-04 23:35:08   \n",
      "3  daily.2019-09-04_23-23-01.csv  DumpTask        2019-09-04 23:35:08   \n",
      "4  daily.2019-09-04_23-23-01.csv  ProxySetupTask  2019-09-04 23:35:08   \n",
      "\n",
      "              end_time  \n",
      "0  2019-09-06 20:33:05  \n",
      "1  2019-09-04 23:36:33  \n",
      "2  2019-09-05 00:00:34  \n",
      "3  2019-09-04 23:35:58  \n",
      "4  2019-09-04 23:51:32  \n"
     ]
    }
   ],
   "source": [
    "catt = tt[['case', 'activity','start_time','end_time']]\n",
    "\n",
    "print(len(catt))\n",
    "print(catt.head())\n",
    "catt.to_csv(OUTPUT_CATT_PATH, index = None, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15687\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "w_call = tt[['case', 'activity','start_time','end_time', 'task_call']]\n",
    "grouped = w_call.groupby(['task_call'],as_index=False)\n",
    "print(len(grouped))\n",
    "#grouped.head()\n",
    "#grouped = grouped[grouped['activity']!='CrawlTask']\n",
    "#grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(start_time, end_time):\n",
    "    start = datetime.datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')\n",
    "    end = datetime.datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')\n",
    "    duration = abs(end - start)\n",
    "    return duration\n",
    "#get_duration(ex['timestamp'][10],ex['timestamp'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15711\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>activity</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>t_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>AllTasks</td>\n",
       "      <td>2019-09-04 23:23:20</td>\n",
       "      <td>2019-09-06 20:33:05</td>\n",
       "      <td>1 day, 21:09:45</td>\n",
       "      <td>45.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:36:33</td>\n",
       "      <td>0:01:25</td>\n",
       "      <td>0.023611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-05 00:00:34</td>\n",
       "      <td>0:25:26</td>\n",
       "      <td>0.423889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:35:58</td>\n",
       "      <td>0:00:50</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>ProxySetupTask</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:51:32</td>\n",
       "      <td>0:16:24</td>\n",
       "      <td>0.273333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            case        activity           start_time  \\\n",
       "0  daily.2019-09-04_23-23-01.csv        AllTasks  2019-09-04 23:23:20   \n",
       "1  daily.2019-09-04_23-23-01.csv        DumpTask  2019-09-04 23:35:08   \n",
       "2  daily.2019-09-04_23-23-01.csv        DumpTask  2019-09-04 23:35:08   \n",
       "3  daily.2019-09-04_23-23-01.csv        DumpTask  2019-09-04 23:35:08   \n",
       "4  daily.2019-09-04_23-23-01.csv  ProxySetupTask  2019-09-04 23:35:08   \n",
       "\n",
       "              end_time         duration  t_duration  \n",
       "0  2019-09-06 20:33:05  1 day, 21:09:45   45.162500  \n",
       "1  2019-09-04 23:36:33          0:01:25    0.023611  \n",
       "2  2019-09-05 00:00:34          0:25:26    0.423889  \n",
       "3  2019-09-04 23:35:58          0:00:50    0.013889  \n",
       "4  2019-09-04 23:51:32          0:16:24    0.273333  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_duration = tt.copy()\n",
    "w_duration = w_duration[['case', 'activity','start_time','end_time']]\n",
    "w_duration['duration'] = w_duration.apply(lambda row: str(get_duration(row['start_time'],row['end_time'])), axis=1)\n",
    "w_duration['t_duration']= w_duration.apply(lambda row: (get_duration(row['start_time'],row['end_time']).total_seconds())/60/60, axis=1)\n",
    "\n",
    "\n",
    "w_duration = w_duration[['case','activity','start_time','end_time', 'duration', 't_duration']]\n",
    "print(len(w_duration))\n",
    "w_duration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>counts</th>\n",
       "      <th>t_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtractTask</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.964722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CrawlTask</td>\n",
       "      <td>1992</td>\n",
       "      <td>6.859167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DumpTask</td>\n",
       "      <td>189</td>\n",
       "      <td>3.421111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvertDumpTask</td>\n",
       "      <td>166</td>\n",
       "      <td>0.354444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GroupTask</td>\n",
       "      <td>31</td>\n",
       "      <td>22.866944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          activity  counts  t_duration\n",
       "0      ExtractTask    2014    1.964722\n",
       "1        CrawlTask    1992    6.859167\n",
       "2         DumpTask     189    3.421111\n",
       "3  ConvertDumpTask     166    0.354444\n",
       "4        GroupTask      31   22.866944"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_long_tasks = w_duration.head(5000)\n",
    "max_duration = top_long_tasks.groupby(['activity'], sort=False)['t_duration'].max().reset_index()\n",
    "#.reset_index(name='max_duration').sort_values(by=['max_duration'], ascending=False)\n",
    "counts = top_long_tasks.groupby(['activity']).size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)\n",
    "act_group = pd.merge(counts, max_duration, on=['activity'], how='outer')\n",
    "act_group = act_group.sort_values(by=['counts'], ascending = False)\n",
    "print(len(act_group))\n",
    "act_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/trustyou/home/andream/nfs/processmining/minilogs/daily/logs/\n",
      "catts_daily.2019-09-.csv\n",
      "catts_daily.2019-09-01_09-29-01.csv\n"
     ]
    }
   ],
   "source": [
    "csv_list = []\n",
    "print(LUIGI_LOG_PATH)\n",
    "for filename in os.listdir(LUIGI_LOG_PATH+'../'):\n",
    "    if filename.endswith('.csv'):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['catts_daily.2019-09-.csv']\n",
      "15711\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>activity</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>AllTasks</td>\n",
       "      <td>2019-09-04 23:23:20</td>\n",
       "      <td>2019-09-06 20:33:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:36:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-05 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:35:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>ProxySetupTask</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:51:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            case        activity           start_time  \\\n",
       "0  daily.2019-09-04_23-23-01.csv        AllTasks  2019-09-04 23:23:20   \n",
       "1  daily.2019-09-04_23-23-01.csv        DumpTask  2019-09-04 23:35:08   \n",
       "2  daily.2019-09-04_23-23-01.csv        DumpTask  2019-09-04 23:35:08   \n",
       "3  daily.2019-09-04_23-23-01.csv        DumpTask  2019-09-04 23:35:08   \n",
       "4  daily.2019-09-04_23-23-01.csv  ProxySetupTask  2019-09-04 23:35:08   \n",
       "\n",
       "              end_time  \n",
       "0  2019-09-06 20:33:05  \n",
       "1  2019-09-04 23:36:33  \n",
       "2  2019-09-05 00:00:34  \n",
       "3  2019-09-04 23:35:58  \n",
       "4  2019-09-04 23:51:32  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_list = []\n",
    "appended_df = pd.DataFrame()\n",
    "#LUIGI_LOG_PATH='/usr/local/trustyou/home/andream/nfs/processmining/minilogs/table-precomp/logs/october/'\n",
    "LUIGI_LOG_PATH = '/usr/local/trustyou/home/andream/nfs/processmining/minilogs/daily/'\n",
    "#LUIGI_LOG_PATH = '/usr/local/trustyou/home/andream/nfs/processmining/minilogs/table-precomp/logs/tch/'\n",
    "\n",
    "for filename in os.listdir(LUIGI_LOG_PATH):\n",
    "    if filename.endswith('-.csv') and filename.startswith('catts'):\n",
    "        log_path = LUIGI_LOG_PATH+'/'+filename\n",
    "        csv_list.append(filename)\n",
    "        df = pd.read_csv(log_path, index_col=False)\n",
    "        appended_df = appended_df.append(df)\n",
    "\n",
    "#appended_df\n",
    "csv_list.sort()\n",
    "print(csv_list)\n",
    "print(len(appended_df))\n",
    "appended_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15711\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>activity</th>\n",
       "      <th>task_call</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>AllTasks</td>\n",
       "      <td>AllTasks</td>\n",
       "      <td>2019-09-04 23:23:20</td>\n",
       "      <td>2019-09-06 20:33:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=daily...</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:36:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=regul...</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-05 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=repro...</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:35:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>ProxySetupTask</td>\n",
       "      <td>ProxySetupTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep)\\n</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:51:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            case        activity  \\\n",
       "0  daily.2019-09-04_23-23-01.csv        AllTasks   \n",
       "1  daily.2019-09-04_23-23-01.csv        DumpTask   \n",
       "2  daily.2019-09-04_23-23-01.csv        DumpTask   \n",
       "3  daily.2019-09-04_23-23-01.csv        DumpTask   \n",
       "4  daily.2019-09-04_23-23-01.csv  ProxySetupTask   \n",
       "\n",
       "                                                                                             task_call  \\\n",
       "0                                                                                             AllTasks   \n",
       "1  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=daily...   \n",
       "2  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=regul...   \n",
       "3  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=repro...   \n",
       "4                ProxySetupTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep)\\n   \n",
       "\n",
       "            start_time             end_time  \n",
       "0  2019-09-04 23:23:20  2019-09-06 20:33:05  \n",
       "1  2019-09-04 23:35:08  2019-09-04 23:36:33  \n",
       "2  2019-09-04 23:35:08  2019-09-05 00:00:34  \n",
       "3  2019-09-04 23:35:08  2019-09-04 23:35:58  \n",
       "4  2019-09-04 23:35:08  2019-09-04 23:51:32  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_calls = tt.copy()[['case', 'activity', 'task_call', 'start_time', 'end_time']]\n",
    "print(len(task_calls))\n",
    "task_calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15711  lines in catt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtractTask</td>\n",
       "      <td>6346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CrawlTask</td>\n",
       "      <td>6326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DumpTask</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ConvertDumpTask</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GroupTask</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           activity  counts\n",
       "19      ExtractTask    6346\n",
       "14        CrawlTask    6326\n",
       "17         DumpTask     585\n",
       "8   ConvertDumpTask     533\n",
       "24        GroupTask      89"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = task_calls.groupby(['activity']).size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)\n",
    "print(len(task_calls),' lines in catt')\n",
    "counts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67  different activities\n",
      "13  cases\n",
      "\n",
      "15687 unique task_calls\n",
      "24 duplicated task_calls\n",
      "9  unique duplicated task_calls\n"
     ]
    }
   ],
   "source": [
    "unique_act = task_calls['activity'].unique().tolist()\n",
    "print(len(unique_act), ' different activities')\n",
    "\n",
    "unique_trace = task_calls['case'].unique().tolist()\n",
    "print(len(unique_trace), ' cases\\n')\n",
    "\n",
    "unique_task_call = task_calls['task_call'].unique().tolist()\n",
    "print(len(unique_task_call), 'unique task_calls')\n",
    "print(len(task_calls)-len(unique_task_call), 'duplicated task_calls')\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "dfObj = pd.DataFrame(task_calls, columns=['case','task_call','activity','start_time', 'end_time'])\n",
    "duplicated_task_calls = dfObj[dfObj.duplicated(['case','task_call','end_time'])].sort_values(by=['task_call'])['task_call'].unique().tolist()\n",
    "print(len(duplicated_task_calls),' unique duplicated task_calls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_long_tasks = w_duration.head(5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parameters(task_call):\n",
    "    task_split = task_call.split('(', 1)\n",
    "    parameters = {}\n",
    "    next_key = None\n",
    "    key = None\n",
    "    if len(task_split)>1: \n",
    "        reversed_parameters = [''.join(reversed(element)) for element in task_split[1:]][0].split(')', 1)[1:]\n",
    "        forward_parameters = [''.join(reversed(element)) for element in reversed_parameters][0]\n",
    "        parameters_call = forward_parameters.split('=')\n",
    "        #print(task_call)\n",
    "        for i, element in enumerate(parameters_call): \n",
    "            if next_key is None and key is None: \n",
    "                key = element\n",
    "                continue\n",
    "            if next_key is not None:\n",
    "                key = next_key\n",
    "            if element.startswith('('):\n",
    "                next_key = re.search('\\), (.*)', element)\n",
    "                value = re.search('(\\(.*)\\), ', element)\n",
    "            else: \n",
    "                next_key = re.search(', (.*)', element)\n",
    "                value = re.search('(.*), ', element)\n",
    "            if next_key is None: \n",
    "                #Find out if elem is key or value\n",
    "                value = element\n",
    "            else:\n",
    "                next_key = next_key.group(1)\n",
    "                if element.startswith('('):\n",
    "                    value = value.group(0)[:-2]\n",
    "                else: \n",
    "                    value = value.group(1)\n",
    "            #print('A: ', key, value)               \n",
    "            parameters[key] = value\n",
    "    return parameters\n",
    "\n",
    "#print(extract_parameters('AllTasks'))\n",
    "#extract_parameters(\"DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=review, kvs=(('table_name', u'review_2018_3'),), target_filename=review_2018_3, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-04_23-23-01\n",
      "2019-09-04_23-23-01\n"
     ]
    }
   ],
   "source": [
    "#task_calls[task_calls['task_call']=='CrawlTask(date=2019-09-15_01-41-01, prev_date=2019-09-13_04-11-01, chunk=02, partition=00007, crawler=creepy-crawly)\\n']\n",
    "#task_calls[task_calls['task_call']=='GroupTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=02, datacenter=eu, inc=True, deploy=False, datastore=mongo)\\n']\n",
    "#task_calls[task_calls['task_call']=='AllTasks'].sort_values(by='case')\n",
    "#print(task_calls.head())\n",
    "task_calls['parameters'] = task_calls.apply(lambda row: extract_parameters(row['task_call']), axis=1)\n",
    "#print(task_calls[['task_call', 'parameters']].head(50))\n",
    "print(task_calls['parameters'][1]['date'])\n",
    "print(task_calls.iloc[1]['parameters']['date'])\n",
    "#print(task_calls['parameters'][1]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "#task_calls[task_calls['activity']=='CrawlChunkTask'][['case','activity','parameters']].head()\n",
    "#print(task_calls.iloc[1]['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>activity</th>\n",
       "      <th>task_call</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>parameters</th>\n",
       "      <th>date</th>\n",
       "      <th>prev_date</th>\n",
       "      <th>chunk</th>\n",
       "      <th>sql_filename</th>\n",
       "      <th>kvs</th>\n",
       "      <th>target_filename</th>\n",
       "      <th>db_host</th>\n",
       "      <th>db_port</th>\n",
       "      <th>db_user</th>\n",
       "      <th>db_name</th>\n",
       "      <th>output_format</th>\n",
       "      <th>filename_chunk</th>\n",
       "      <th>what</th>\n",
       "      <th>crawler</th>\n",
       "      <th>partition</th>\n",
       "      <th>sql_templ_filename</th>\n",
       "      <th>parent</th>\n",
       "      <th>schema</th>\n",
       "      <th>archive_hdfs_filepath</th>\n",
       "      <th>host</th>\n",
       "      <th>port</th>\n",
       "      <th>namespace</th>\n",
       "      <th>table</th>\n",
       "      <th>datacenter</th>\n",
       "      <th>inc</th>\n",
       "      <th>deploy</th>\n",
       "      <th>datastore</th>\n",
       "      <th>send_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>AllTasks</td>\n",
       "      <td>AllTasks</td>\n",
       "      <td>2019-09-04 23:23:20</td>\n",
       "      <td>2019-09-06 20:33:05</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=daily_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:36:33</td>\n",
       "      <td>{'date': '2019-09-04_23-23-01', 'prev_date': '2019-09-03_03-44-01', 'chunk': 'prep', 'sql_filename': 'daily_urls', 'kvs': 'None', 'target_filename': 'None', 'db_host': 'db.trustyou.com', 'db_port': '5432', 'db_user': 'daily', 'db_name': 'ty_analytic'}</td>\n",
       "      <td>2019-09-04_23-23-01</td>\n",
       "      <td>2019-09-03_03-44-01</td>\n",
       "      <td>prep</td>\n",
       "      <td>daily_urls</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>db.trustyou.com</td>\n",
       "      <td>5432</td>\n",
       "      <td>daily</td>\n",
       "      <td>ty_analytic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=regular_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-05 00:00:34</td>\n",
       "      <td>{'date': '2019-09-04_23-23-01', 'prev_date': '2019-09-03_03-44-01', 'chunk': 'prep', 'sql_filename': 'regular_urls', 'kvs': 'None', 'target_filename': 'None', 'db_host': 'db.trustyou.com', 'db_port': '5432', 'db_user': 'daily', 'db_name': 'ty_analytic'}</td>\n",
       "      <td>2019-09-04_23-23-01</td>\n",
       "      <td>2019-09-03_03-44-01</td>\n",
       "      <td>prep</td>\n",
       "      <td>regular_urls</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>db.trustyou.com</td>\n",
       "      <td>5432</td>\n",
       "      <td>daily</td>\n",
       "      <td>ty_analytic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask</td>\n",
       "      <td>DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=reprocess_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:35:58</td>\n",
       "      <td>{'date': '2019-09-04_23-23-01', 'prev_date': '2019-09-03_03-44-01', 'chunk': 'prep', 'sql_filename': 'reprocess_urls', 'kvs': 'None', 'target_filename': 'None', 'db_host': 'db.trustyou.com', 'db_port': '5432', 'db_user': 'daily', 'db_name': 'ty_analytic'}</td>\n",
       "      <td>2019-09-04_23-23-01</td>\n",
       "      <td>2019-09-03_03-44-01</td>\n",
       "      <td>prep</td>\n",
       "      <td>reprocess_urls</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>db.trustyou.com</td>\n",
       "      <td>5432</td>\n",
       "      <td>daily</td>\n",
       "      <td>ty_analytic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>ProxySetupTask</td>\n",
       "      <td>ProxySetupTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep)\\n</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:51:32</td>\n",
       "      <td>{'date': '2019-09-04_23-23-01', 'prev_date': '2019-09-03_03-44-01', 'chunk': 'prep'}</td>\n",
       "      <td>2019-09-04_23-23-01</td>\n",
       "      <td>2019-09-03_03-44-01</td>\n",
       "      <td>prep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            case        activity  \\\n",
       "0  daily.2019-09-04_23-23-01.csv  AllTasks         \n",
       "1  daily.2019-09-04_23-23-01.csv  DumpTask         \n",
       "2  daily.2019-09-04_23-23-01.csv  DumpTask         \n",
       "3  daily.2019-09-04_23-23-01.csv  DumpTask         \n",
       "4  daily.2019-09-04_23-23-01.csv  ProxySetupTask   \n",
       "\n",
       "                                                                                                                                                                                                                 task_call  \\\n",
       "0  AllTasks                                                                                                                                                                                                                  \n",
       "1  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=daily_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n       \n",
       "2  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=regular_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n     \n",
       "3  DumpTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep, sql_filename=reprocess_urls, kvs=None, target_filename=None, db_host=db.trustyou.com, db_port=5432, db_user=daily, db_name=ty_analytic)\\n   \n",
       "4  ProxySetupTask(date=2019-09-04_23-23-01, prev_date=2019-09-03_03-44-01, chunk=prep)\\n                                                                                                                                     \n",
       "\n",
       "            start_time             end_time  \\\n",
       "0  2019-09-04 23:23:20  2019-09-06 20:33:05   \n",
       "1  2019-09-04 23:35:08  2019-09-04 23:36:33   \n",
       "2  2019-09-04 23:35:08  2019-09-05 00:00:34   \n",
       "3  2019-09-04 23:35:08  2019-09-04 23:35:58   \n",
       "4  2019-09-04 23:35:08  2019-09-04 23:51:32   \n",
       "\n",
       "                                                                                                                                                                                                                                                        parameters  \\\n",
       "0  {}                                                                                                                                                                                                                                                                \n",
       "1  {'date': '2019-09-04_23-23-01', 'prev_date': '2019-09-03_03-44-01', 'chunk': 'prep', 'sql_filename': 'daily_urls', 'kvs': 'None', 'target_filename': 'None', 'db_host': 'db.trustyou.com', 'db_port': '5432', 'db_user': 'daily', 'db_name': 'ty_analytic'}       \n",
       "2  {'date': '2019-09-04_23-23-01', 'prev_date': '2019-09-03_03-44-01', 'chunk': 'prep', 'sql_filename': 'regular_urls', 'kvs': 'None', 'target_filename': 'None', 'db_host': 'db.trustyou.com', 'db_port': '5432', 'db_user': 'daily', 'db_name': 'ty_analytic'}     \n",
       "3  {'date': '2019-09-04_23-23-01', 'prev_date': '2019-09-03_03-44-01', 'chunk': 'prep', 'sql_filename': 'reprocess_urls', 'kvs': 'None', 'target_filename': 'None', 'db_host': 'db.trustyou.com', 'db_port': '5432', 'db_user': 'daily', 'db_name': 'ty_analytic'}   \n",
       "4  {'date': '2019-09-04_23-23-01', 'prev_date': '2019-09-03_03-44-01', 'chunk': 'prep'}                                                                                                                                                                              \n",
       "\n",
       "                  date            prev_date chunk    sql_filename   kvs  \\\n",
       "0  NaN                  NaN                  NaN   NaN             NaN    \n",
       "1  2019-09-04_23-23-01  2019-09-03_03-44-01  prep  daily_urls      None   \n",
       "2  2019-09-04_23-23-01  2019-09-03_03-44-01  prep  regular_urls    None   \n",
       "3  2019-09-04_23-23-01  2019-09-03_03-44-01  prep  reprocess_urls  None   \n",
       "4  2019-09-04_23-23-01  2019-09-03_03-44-01  prep  NaN             NaN    \n",
       "\n",
       "  target_filename          db_host db_port db_user      db_name output_format  \\\n",
       "0  NaN             NaN              NaN     NaN     NaN          NaN            \n",
       "1  None            db.trustyou.com  5432    daily   ty_analytic  NaN            \n",
       "2  None            db.trustyou.com  5432    daily   ty_analytic  NaN            \n",
       "3  None            db.trustyou.com  5432    daily   ty_analytic  NaN            \n",
       "4  NaN             NaN              NaN     NaN     NaN          NaN            \n",
       "\n",
       "  filename_chunk what crawler partition sql_templ_filename parent schema  \\\n",
       "0  NaN            NaN  NaN     NaN       NaN                NaN    NaN     \n",
       "1  NaN            NaN  NaN     NaN       NaN                NaN    NaN     \n",
       "2  NaN            NaN  NaN     NaN       NaN                NaN    NaN     \n",
       "3  NaN            NaN  NaN     NaN       NaN                NaN    NaN     \n",
       "4  NaN            NaN  NaN     NaN       NaN                NaN    NaN     \n",
       "\n",
       "  archive_hdfs_filepath host port namespace table datacenter  inc deploy  \\\n",
       "0  NaN                   NaN  NaN  NaN       NaN   NaN        NaN  NaN     \n",
       "1  NaN                   NaN  NaN  NaN       NaN   NaN        NaN  NaN     \n",
       "2  NaN                   NaN  NaN  NaN       NaN   NaN        NaN  NaN     \n",
       "3  NaN                   NaN  NaN  NaN       NaN   NaN        NaN  NaN     \n",
       "4  NaN                   NaN  NaN  NaN       NaN   NaN        NaN  NaN     \n",
       "\n",
       "  datastore send_to  \n",
       "0  NaN       NaN     \n",
       "1  NaN       NaN     \n",
       "2  NaN       NaN     \n",
       "3  NaN       NaN     \n",
       "4  NaN       NaN     "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "expanded_params = pd.concat([task_calls[:], task_calls['parameters'].apply(pd.Series)], axis=1)\n",
    "len(expanded_params)\n",
    "expanded_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case', 'activity', 'task_call', 'start_time', 'end_time', 'parameters',\n",
       "       'date', 'prev_date', 'chunk', 'sql_filename', 'kvs', 'target_filename',\n",
       "       'db_host', 'db_port', 'db_user', 'db_name', 'output_format',\n",
       "       'filename_chunk', 'what', 'crawler', 'partition', 'sql_templ_filename',\n",
       "       'parent', 'schema', 'archive_hdfs_filepath', 'host', 'port',\n",
       "       'namespace', 'table', 'datacenter', 'inc', 'deploy', 'datastore',\n",
       "       'send_to'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_selection = expanded_params[expanded_params['activity']=='CrawlChunkTask'].sort_values(by='case')\n",
    "activity_selection.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['case', 'activity', 'task_call', 'start_time', 'end_time', 'parameters',\n",
      "       'date', 'prev_date', 'chunk', 'crawler'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>activity</th>\n",
       "      <th>task_call</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>parameters</th>\n",
       "      <th>date</th>\n",
       "      <th>prev_date</th>\n",
       "      <th>chunk</th>\n",
       "      <th>crawler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15655</th>\n",
       "      <td>daily.2019-09-01_09-29-01.csv</td>\n",
       "      <td>CrawlChunkTask</td>\n",
       "      <td>CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=02, crawler=creepy-crawly)\\n</td>\n",
       "      <td>2019-09-02 19:09:16</td>\n",
       "      <td>2019-09-02 19:10:29</td>\n",
       "      <td>{'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '02', 'crawler': 'creepy-crawly'}</td>\n",
       "      <td>2019-09-01_09-29-01</td>\n",
       "      <td>2019-08-30_13-45-01</td>\n",
       "      <td>02</td>\n",
       "      <td>creepy-crawly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15351</th>\n",
       "      <td>daily.2019-09-01_09-29-01.csv</td>\n",
       "      <td>CrawlChunkTask</td>\n",
       "      <td>CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=02, crawler=ty-superman)\\n</td>\n",
       "      <td>2019-09-02 02:26:42</td>\n",
       "      <td>2019-09-02 02:26:42</td>\n",
       "      <td>{'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '02', 'crawler': 'ty-superman'}</td>\n",
       "      <td>2019-09-01_09-29-01</td>\n",
       "      <td>2019-08-30_13-45-01</td>\n",
       "      <td>02</td>\n",
       "      <td>ty-superman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15223</th>\n",
       "      <td>daily.2019-09-01_09-29-01.csv</td>\n",
       "      <td>CrawlChunkTask</td>\n",
       "      <td>CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=01, crawler=creepy-crawly)\\n</td>\n",
       "      <td>2019-09-01 21:59:16</td>\n",
       "      <td>2019-09-01 22:01:38</td>\n",
       "      <td>{'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '01', 'crawler': 'creepy-crawly'}</td>\n",
       "      <td>2019-09-01_09-29-01</td>\n",
       "      <td>2019-08-30_13-45-01</td>\n",
       "      <td>01</td>\n",
       "      <td>creepy-crawly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14520</th>\n",
       "      <td>daily.2019-09-01_09-29-01.csv</td>\n",
       "      <td>CrawlChunkTask</td>\n",
       "      <td>CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=03, crawler=ty-superman)\\n</td>\n",
       "      <td>2019-09-01 11:06:41</td>\n",
       "      <td>2019-09-01 11:06:42</td>\n",
       "      <td>{'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '03', 'crawler': 'ty-superman'}</td>\n",
       "      <td>2019-09-01_09-29-01</td>\n",
       "      <td>2019-08-30_13-45-01</td>\n",
       "      <td>03</td>\n",
       "      <td>ty-superman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14518</th>\n",
       "      <td>daily.2019-09-01_09-29-01.csv</td>\n",
       "      <td>CrawlChunkTask</td>\n",
       "      <td>CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=01, crawler=ty-superman)\\n</td>\n",
       "      <td>2019-09-01 11:06:34</td>\n",
       "      <td>2019-09-01 11:06:35</td>\n",
       "      <td>{'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '01', 'crawler': 'ty-superman'}</td>\n",
       "      <td>2019-09-01_09-29-01</td>\n",
       "      <td>2019-08-30_13-45-01</td>\n",
       "      <td>01</td>\n",
       "      <td>ty-superman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                case        activity  \\\n",
       "15655  daily.2019-09-01_09-29-01.csv  CrawlChunkTask   \n",
       "15351  daily.2019-09-01_09-29-01.csv  CrawlChunkTask   \n",
       "15223  daily.2019-09-01_09-29-01.csv  CrawlChunkTask   \n",
       "14520  daily.2019-09-01_09-29-01.csv  CrawlChunkTask   \n",
       "14518  daily.2019-09-01_09-29-01.csv  CrawlChunkTask   \n",
       "\n",
       "                                                                                                        task_call  \\\n",
       "15655  CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=02, crawler=creepy-crawly)\\n   \n",
       "15351  CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=02, crawler=ty-superman)\\n     \n",
       "15223  CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=01, crawler=creepy-crawly)\\n   \n",
       "14520  CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=03, crawler=ty-superman)\\n     \n",
       "14518  CrawlChunkTask(date=2019-09-01_09-29-01, prev_date=2019-08-30_13-45-01, chunk=01, crawler=ty-superman)\\n     \n",
       "\n",
       "                start_time             end_time  \\\n",
       "15655  2019-09-02 19:09:16  2019-09-02 19:10:29   \n",
       "15351  2019-09-02 02:26:42  2019-09-02 02:26:42   \n",
       "15223  2019-09-01 21:59:16  2019-09-01 22:01:38   \n",
       "14520  2019-09-01 11:06:41  2019-09-01 11:06:42   \n",
       "14518  2019-09-01 11:06:34  2019-09-01 11:06:35   \n",
       "\n",
       "                                                                                                           parameters  \\\n",
       "15655  {'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '02', 'crawler': 'creepy-crawly'}   \n",
       "15351  {'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '02', 'crawler': 'ty-superman'}     \n",
       "15223  {'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '01', 'crawler': 'creepy-crawly'}   \n",
       "14520  {'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '03', 'crawler': 'ty-superman'}     \n",
       "14518  {'date': '2019-09-01_09-29-01', 'prev_date': '2019-08-30_13-45-01', 'chunk': '01', 'crawler': 'ty-superman'}     \n",
       "\n",
       "                      date            prev_date chunk        crawler  \n",
       "15655  2019-09-01_09-29-01  2019-08-30_13-45-01  02    creepy-crawly  \n",
       "15351  2019-09-01_09-29-01  2019-08-30_13-45-01  02    ty-superman    \n",
       "15223  2019-09-01_09-29-01  2019-08-30_13-45-01  01    creepy-crawly  \n",
       "14520  2019-09-01_09-29-01  2019-08-30_13-45-01  03    ty-superman    \n",
       "14518  2019-09-01_09-29-01  2019-08-30_13-45-01  01    ty-superman    "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_selection = activity_selection.dropna(axis=1,how='all')\n",
    "\n",
    "print(activity_selection.columns)\n",
    "activity_selection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 rows:\n",
      "\n",
      "                                case        activity           start_time  \\\n",
      "15655  daily.2019-09-01_09-29-01.csv  CrawlChunkTask  2019-09-02 19:09:16   \n",
      "\n",
      "                  end_time  \n",
      "15655  2019-09-02 19:10:29  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>different_groups_per_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>activity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crawler</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chunk</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prev_date</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>date</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>task_call</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>end_time</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>start_time</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       column different_groups_per_column\n",
       "8  activity    1                         \n",
       "2  crawler     2                         \n",
       "0  chunk       3                         \n",
       "1  prev_date   13                        \n",
       "4  case        13                        \n",
       "6  date        13                        \n",
       "3  task_call   75                        \n",
       "5  end_time    75                        \n",
       "7  start_time  75                        "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "non_str_columns = ['parameters']\n",
    "column_selection = set(activity_selection.columns) - set(non_str_columns)\n",
    "\n",
    "#counts = activity_selection.groupby(['db_port']).size().reset_index(name='counts').sort_values(by=['counts'])\n",
    "\n",
    "print(len(activity_selection),'rows:\\n')\n",
    "print(activity_selection.head(1)[['case','activity','start_time','end_time']])\n",
    "\n",
    "groups_description = pd.DataFrame(columns=['column','different_groups_per_column'])\n",
    "for column in column_selection: \n",
    "    #print(column,len(clean_activity_selection.groupby([column]).size().reset_index(name='counts').sort_values(by=['counts'])))\n",
    "    groups_description = groups_description.append([{'column': column, 'different_groups_per_column': len(activity_selection.groupby([column]).size().reset_index(name='counts').sort_values(by=['counts']))}])\n",
    "groups_description = groups_description.reset_index()[['column','different_groups_per_column']].sort_values(by=['different_groups_per_column'])\n",
    "\n",
    "groups_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar number of groups with multiple appereances in Groupbys:  [13, 75]\n",
      "Groups with similar number of groups:  [['prev_date', 'case', 'date'], ['task_call', 'end_time', 'start_time']]\n"
     ]
    }
   ],
   "source": [
    "similar_group_descr = groups_description.groupby(by=['different_groups_per_column']).size().reset_index(name='similar_group')\n",
    "similar_group_counts = similar_group_descr[similar_group_descr['similar_group']>1]['different_groups_per_column'].tolist()\n",
    "print('Similar number of groups with multiple appereances in Groupbys: ', similar_group_counts)\n",
    "\n",
    "drop_candidates = []\n",
    "for group in similar_group_counts: \n",
    "    parameters = groups_description[groups_description['different_groups_per_column']==group]['column'].tolist()\n",
    "    drop_candidates.append(parameters)\n",
    "print('Groups with similar number of groups: ', drop_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_parametrized</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CrawlChunkTask(crawler=creepy-crawly)(chunk=01)</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CrawlChunkTask(crawler=ty-superman)(chunk=01)</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CrawlChunkTask(crawler=ty-superman)(chunk=03)</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CrawlChunkTask(crawler=creepy-crawly)(chunk=02)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CrawlChunkTask(crawler=creepy-crawly)(chunk=03)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CrawlChunkTask(crawler=ty-superman)(chunk=02)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             activity_parametrized  counts\n",
       "0  CrawlChunkTask(crawler=creepy-crawly)(chunk=01)  13    \n",
       "3  CrawlChunkTask(crawler=ty-superman)(chunk=01)    13    \n",
       "5  CrawlChunkTask(crawler=ty-superman)(chunk=03)    13    \n",
       "1  CrawlChunkTask(crawler=creepy-crawly)(chunk=02)  12    \n",
       "2  CrawlChunkTask(crawler=creepy-crawly)(chunk=03)  12    \n",
       "4  CrawlChunkTask(crawler=ty-superman)(chunk=02)    12    "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_activity_new_name(old_name, column_key, column_value):\n",
    "    if column_key is None: \n",
    "        return old_name\n",
    "    activity_name = str(old_name)+'('+str(column_key)\n",
    "    if column_value is np.nan: \n",
    "        activity_name = activity_name+'=None'\n",
    "    else: \n",
    "        activity_name = activity_name+'='+str(column_value)\n",
    "    activity_name = activity_name +')'\n",
    "    return activity_name\n",
    "\n",
    "def clean_insignificant_columns(df, drop_candidates):\n",
    "    BLACKLIST = []\n",
    "    WHITELIST = ['parameters', 'task_call']\n",
    "    columns_to_drop = []\n",
    "    verified_candidates = []\n",
    "    number_of_cases = len(df.groupby(['case']))\n",
    "    flag =0\n",
    "    for group_candidates in drop_candidates:\n",
    "        for candidate in (set(group_candidates)-set(WHITELIST)): \n",
    "            group_counts = df.groupby([candidate]).size().reset_index(name='counts').sort_values(by=['counts'])['counts'].tolist()\n",
    "            #print(group_counts)\n",
    "            if 'date' in candidate:\n",
    "                verified_candidates.append(candidate)\n",
    "            if len(group_counts)==1 or len(group_counts)==number_of_cases:\n",
    "                if (all(item == group_counts[0] for item in group_counts) and (group_counts[0]*len(group_counts))== len(df)):\n",
    "                    #print(group_counts)\n",
    "                    #or all(item == number_of_cases for item in group_counts)\n",
    "                    verified_candidates.append(candidate)\n",
    "            else:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag:\n",
    "            first_candidate_counts = df.groupby([group_candidates[0]]).size().reset_index(name='counts')['counts'].tolist()\n",
    "            if (all(first_candidate_counts==df.groupby([item]).size().reset_index(name='counts')['counts'].tolist() for item in group_candidates)):\n",
    "                all(verified_candidates.append(item) for item in group_candidates[:-1])\n",
    "            flag = 0\n",
    "    columns_to_drop = set(verified_candidates)-set(catt.columns)-set(WHITELIST)\n",
    "    df = df.drop(columns_to_drop, axis=1)\n",
    "    #print('Dropped: ',columns_to_drop, ' for activity: ', df['activity'].iloc[0])\n",
    "    \n",
    "    #if (set(df.columns)-set(catt.columns)-set({'parameters', 'task_call'})==set()):\n",
    "    df['activity_parametrized'] = df['activity']\n",
    "    retained_columns = set(df.columns)-set(catt.columns)-set(WHITELIST)\n",
    "    if not (retained_columns==set()):\n",
    "        for column in retained_columns-set({'activity_parametrized'}):\n",
    "            df['activity_parametrized'] = df.apply(lambda row: get_activity_new_name(row['activity_parametrized'], column, row[column]), axis=1)\n",
    "    #print(df['activity'].iloc[0], 'was added', retained_columns-set({'activity_parametrized'}))\n",
    "    return df \n",
    "\n",
    "    \n",
    "clean_dump = clean_insignificant_columns(activity_selection, drop_candidates)\n",
    "#print(clean_dump.head())\n",
    "counts = clean_dump.groupby(['activity_parametrized']).size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)\n",
    "counts = counts.sort_values(by=['counts'], ascending = False)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>activity</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>AllTasks</td>\n",
       "      <td>2019-09-04 23:23:20</td>\n",
       "      <td>2019-09-06 20:33:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask(sql_filename=daily_urls)(chunk=prep)(kvs=None)</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:36:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask(sql_filename=regular_urls)(chunk=prep)(kvs=None)</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-05 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>DumpTask(sql_filename=reprocess_urls)(chunk=prep)(kvs=None)</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:35:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daily.2019-09-04_23-23-01.csv</td>\n",
       "      <td>ProxySetupTask</td>\n",
       "      <td>2019-09-04 23:35:08</td>\n",
       "      <td>2019-09-04 23:51:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            case  \\\n",
       "0  daily.2019-09-04_23-23-01.csv   \n",
       "1  daily.2019-09-04_23-23-01.csv   \n",
       "2  daily.2019-09-04_23-23-01.csv   \n",
       "3  daily.2019-09-04_23-23-01.csv   \n",
       "4  daily.2019-09-04_23-23-01.csv   \n",
       "\n",
       "                                                      activity  \\\n",
       "0  AllTasks                                                      \n",
       "1  DumpTask(sql_filename=daily_urls)(chunk=prep)(kvs=None)       \n",
       "2  DumpTask(sql_filename=regular_urls)(chunk=prep)(kvs=None)     \n",
       "3  DumpTask(sql_filename=reprocess_urls)(chunk=prep)(kvs=None)   \n",
       "4  ProxySetupTask                                                \n",
       "\n",
       "            start_time             end_time  \n",
       "0  2019-09-04 23:23:20  2019-09-06 20:33:05  \n",
       "1  2019-09-04 23:35:08  2019-09-04 23:36:33  \n",
       "2  2019-09-04 23:35:08  2019-09-05 00:00:34  \n",
       "3  2019-09-04 23:35:08  2019-09-04 23:35:58  \n",
       "4  2019-09-04 23:35:08  2019-09-04 23:51:32  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_parametrized_activity(df):\n",
    "    clean_dump = pd.DataFrame()\n",
    "    return_columns = ['activity_parametrized', 'case', 'activity', 'start_time', 'end_time', 'task_call']\n",
    "    non_str_columns = ['parameters']\n",
    "    df = df.replace('None', np.nan)\n",
    "    activities = df.groupby(['activity']).size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)['activity'].tolist()\n",
    "    for activity in activities:\n",
    "        activity_selection = df[df['activity']==activity].sort_values(by='case')\n",
    "        activity_selection = activity_selection.dropna(axis=1,how='all')\n",
    "        column_selection = set(activity_selection.columns) - set(non_str_columns)\n",
    "        \n",
    "        groups_description = pd.DataFrame(columns=['column','different_groups_per_column'])\n",
    "        for column in column_selection: \n",
    "            #print(column,len(clean_activity_selection.groupby([column]).size().reset_index(name='counts').sort_values(by=['counts'])))\n",
    "            groups_description = groups_description.append([{'column': column, 'different_groups_per_column': len(activity_selection.groupby([column]).size().reset_index(name='counts').sort_values(by=['counts']))}])\n",
    "        groups_description = groups_description.reset_index()[['column','different_groups_per_column']].sort_values(by=['different_groups_per_column'])\n",
    "        \n",
    "        similar_group_descr = groups_description.groupby(by=['different_groups_per_column']).size().reset_index(name='similar_group')\n",
    "        similar_group_counts = similar_group_descr[similar_group_descr['similar_group']>1]['different_groups_per_column'].tolist()\n",
    "        #print('Similar number of groups with multiple appereances in Groupbys: ', similar_group_counts)\n",
    "\n",
    "        drop_candidates = []\n",
    "        for group in similar_group_counts: \n",
    "            parameters = groups_description[groups_description['different_groups_per_column']==group]['column'].tolist()\n",
    "            drop_candidates.append(parameters)\n",
    "        #print('Groups with similar number of groups: ', drop_candidates)\n",
    "        clean_dump = clean_dump.append(clean_insignificant_columns(activity_selection, drop_candidates)[return_columns])\n",
    "    df = pd.merge(df, clean_dump, on=return_columns[1:], how='inner')[return_columns]\n",
    "    return df\n",
    "\n",
    "        #print(activity_selection.columns)\n",
    "\n",
    "params_catt = get_parametrized_activity(expanded_params)\n",
    "params_catt['activity'] = params_catt['activity_parametrized']\n",
    "params_catt = params_catt[catt.columns]\n",
    "#print(len(params_catt))\n",
    "params_catt.head()\n",
    "#expanded_params.groupby(['activity']).reset_index(name='counts').sort_values(by=['counts'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15711  lines in catt\n",
      "1248 different activities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>GroupTask(datastore=mongo)(chunk=02)(inc=True)(datacenter=eu)(deploy=False)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>ResyncReviewPropertiesTask(chunk=03)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>GroupTask(datastore=mongo)(chunk=01)(inc=False)(datacenter=eu)(deploy=False)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>ProxySetupTask</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>DumpTask(sql_filename=review)(chunk=prep)(kvs=(('table_name', u'review_2013_1'),))</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                activity  \\\n",
       "1144  GroupTask(datastore=mongo)(chunk=02)(inc=True)(datacenter=eu)(deploy=False)          \n",
       "1202  ResyncReviewPropertiesTask(chunk=03)                                                 \n",
       "1142  GroupTask(datastore=mongo)(chunk=01)(inc=False)(datacenter=eu)(deploy=False)         \n",
       "1167  ProxySetupTask                                                                       \n",
       "596   DumpTask(sql_filename=review)(chunk=prep)(kvs=(('table_name', u'review_2013_1'),))   \n",
       "\n",
       "      counts  \n",
       "1144  15      \n",
       "1202  14      \n",
       "1142  14      \n",
       "1167  14      \n",
       "596   13      "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "counts = params_catt.groupby(['activity']).size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)\n",
    "print(len(params_catt),' lines in catt')\n",
    "print(len(counts), 'different activities')\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_activity_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-066e0d74d162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mverified_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdrop_candidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgroup_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_activity_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgroup_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_activity_selection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mverified_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_activity_selection' is not defined"
     ]
    }
   ],
   "source": [
    "drop_candidates = groups_description[groups_description['different_groups_per_column']==13]['column'].tolist()\n",
    "\n",
    "verified_candidates = []\n",
    "for candidate in drop_candidates: \n",
    "    group_counts = clean_activity_selection.groupby([candidate]).size().reset_index(name='counts').sort_values(by=['counts'])['counts'].tolist()\n",
    "    if all(item == group_counts[0] for item in group_counts) and (group_counts[0]*len(group_counts))== len(clean_activity_selection): \n",
    "        verified_candidates.append(candidate)  \n",
    "columns_to_drop = set(verified_candidates)-set(catt.columns)\n",
    "print(columns_to_drop)\n",
    "clean_case_activity_selection = clean_activity_selection.drop(columns_to_drop, axis=1)\n",
    "\n",
    "clean_case_activity_selection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
